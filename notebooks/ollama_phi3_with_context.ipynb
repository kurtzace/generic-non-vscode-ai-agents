{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23eea19b",
   "metadata": {},
   "source": [
    "# Using Ollama Phi3 with File Context\n",
    "\n",
    "This notebook demonstrates how to use a text file as additional context for prompts sent to the Ollama Phi3 model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b233c8c",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "We will import the `requests` library to make HTTP requests and use standard Python file operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e24dbc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f9bdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987a4b3f",
   "metadata": {},
   "source": [
    "## Set Up Ollama Server Endpoint\n",
    "Define the base URL for your local Ollama server. If authentication is required, set your API key here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f6c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_BASE_URL = \"http://localhost:11434\"  # Change if your Ollama server runs elsewhere\n",
    "MODEL_NAME = \"phi3\"\n",
    "API_KEY = None  # Replace with your API key if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b23e62",
   "metadata": {},
   "source": [
    "## Load Context from a Text File\n",
    "Select and load a text file to use as context for your prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbdbe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the file path as needed\n",
    "context_file_path = \"bdayPrompts.txt\"\n",
    "with open(context_file_path, \"r\") as f:\n",
    "    context_text = f.read()\n",
    "print(\"Loaded context from:\", context_file_path)\n",
    "print(context_text[:300] + (\"...\" if len(context_text) > 300 else \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea2f4e",
   "metadata": {},
   "source": [
    "## Define Function to Call Ollama Phi3 with Context\n",
    "This function sends a prompt and the loaded context to the Ollama Phi3 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9525991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ollama_phi3_with_context(prompt, context, model=MODEL_NAME, base_url=OLLAMA_BASE_URL, api_key=API_KEY):\n",
    "    url = f\"{base_url}/api/chat\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    if api_key:\n",
    "        headers[\"Authorization\"] = f\"Bearer {api_key}\"\n",
    "    # Combine context and prompt\n",
    "    user_message = f\"Context:\\n{context}\\n\\nUser prompt: {prompt}\"\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            result = response.json()\n",
    "            return result.get(\"message\", {}).get(\"content\", \"\")\n",
    "        except Exception:\n",
    "            return response.text\n",
    "    else:\n",
    "        return f\"Error: {response.status_code} - {response.text}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1f2471",
   "metadata": {},
   "source": [
    "## Send User Prompts with Context\n",
    "Enter your prompt below. The context from the file will be included in the request to the Phi3 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba398d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Generate a birthday wish based on the above context.\"\n",
    "response = call_ollama_phi3_with_context(user_prompt, context_text)\n",
    "print(\"Prompt:\", user_prompt)\n",
    "print(\"Response:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
